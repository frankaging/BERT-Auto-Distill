{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run relevance backout here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from random import shuffle\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from model.BERT import *\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from util.optimization import BERTAdam\n",
    "from util.processor import *\n",
    "\n",
    "from util.tokenization import *\n",
    "\n",
    "from util.evaluation import *\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# this imports most of the helpers needed to eval the model\n",
    "from run_classifier import *\n",
    "\n",
    "lrp_data_dir = \"../../results\"\n",
    "vocab_data_dir = \"../../data/uncased_L-12_H-768_A-12/vocab.txt\"\n",
    "sys.path.append(\"..\")\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/30/2020 01:23:11 - INFO - run_classifier -   gpu is out of the picture, let us use CPU\n"
     ]
    }
   ],
   "source": [
    "# Note that this notebook only supports single GPU evaluation\n",
    "# which is sufficient for most of tasks by using lower batch size.\n",
    "IS_CUDA = False\n",
    "if IS_CUDA:\n",
    "    CUDA_DEVICE = \"cuda:5\"\n",
    "    device = torch.device(CUDA_DEVICE)\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    logger.info(\"device %s in total n_gpu %d distributed training\", device, n_gpu)\n",
    "else:\n",
    "    # bad luck, we are on CPU now!\n",
    "    logger.info(\"gpu is out of the picture, let us use CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicate your folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"SST5\"\n",
    "DATA_DIR = \"../../data/dataset/SST5/\"\n",
    "            \n",
    "# \"../../data/uncased_L-12_H-768_A-12/\" is for the default BERT-base pretrain\n",
    "BERT_PATH = \"../../data/uncased_L-12_H-768_A-12/\"\n",
    "MODEL_PATH = \"../../results/\" + TASK_NAME + \"/checkpoint.bin\"\n",
    "EVAL_BATCH_SIZE = 24 # you can tune this down depends on GPU you have.\n",
    "\n",
    "# This loads the task processor for you.\n",
    "processors = {\n",
    "    \"IMDb\":IMDb_Processor,\n",
    "    \"SemEval\":SemEval_Processor,\n",
    "    \"SST5\":SST5_Processor,\n",
    "    \"SST2\":SST2_Processor,\n",
    "    \"SST3\":SST3_Processor,\n",
    "    \"Yelp5\":Yelp5_Processor,\n",
    "    \"Yelp2\":Yelp2_Processor,\n",
    "    \"AdvSA\":AdvSA_Processor\n",
    "}\n",
    "\n",
    "processor = processors[TASK_NAME]()\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/30/2020 01:23:11 - INFO - run_classifier -   model = BERTPretrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_weight = True\n",
      "init_lrp = True\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, tokenizer = \\\n",
    "    getModelOptimizerTokenizer(model_type=\"BERTPretrain\",\n",
    "                               vocab_file=BERT_PATH + \"vocab.txt\",\n",
    "                               embed_file=None,\n",
    "                               bert_config_file=BERT_PATH + \"bert_config.json\",\n",
    "                               init_checkpoint=MODEL_PATH,\n",
    "                               label_list=label_list,\n",
    "                               do_lower_case=True,\n",
    "                               # below is not required for eval\n",
    "                               num_train_steps=20,\n",
    "                               learning_rate=2e-5,\n",
    "                               base_learning_rate=2e-5,\n",
    "                               warmup_proportion=0.1,\n",
    "                               init_lrp=True)\n",
    "model = model.to(device) # send the model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 315/2210 [00:00<00:00, 3137.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "guid= test-0\n",
      "text_a= no movement , no yuks , not much of anything .\n",
      "text_b= None\n",
      "label= 1\n",
      "1000\n",
      "guid= test-1000\n",
      "text_a= has all the poignancy of a hallmark card and all the comedy of a gallagher stand up act .\n",
      "text_b= None\n",
      "label= 2\n",
      "2000\n",
      "guid= test-2000\n",
      "text_a= it 's still worth a look .\n",
      "text_b= None\n",
      "label= 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2210/2210 [00:00<00:00, 2444.65it/s]\n"
     ]
    }
   ],
   "source": [
    "test_examples = processor.get_test_examples(DATA_DIR)\n",
    "test_features = \\\n",
    "    convert_examples_to_features(\n",
    "        test_examples,\n",
    "        label_list,\n",
    "        512,\n",
    "        tokenizer)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in test_features], dtype=torch.long)\n",
    "all_seq_len = torch.tensor([[f.seq_len] for f in test_features], dtype=torch.long)\n",
    "\n",
    "test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "                          all_label_ids, all_seq_len)\n",
    "test_dataloader = DataLoader(test_data, batch_size=EVAL_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call evaluation loop to get accuracy and attribution scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 93/93 [13:47<00:00,  8.90s/it]\n",
      "10/30/2020 01:43:27 - INFO - run_classifier -   ***** Eval results *****\n",
      "10/30/2020 01:43:27 - INFO - run_classifier -     test_loss = 1.2114883481815297\n",
      "\n",
      "10/30/2020 01:43:27 - INFO - run_classifier -     5-class test_accuracy = 0.5425339366515837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we did not exclude gradients, for attribution methods\n",
    "model.eval() # this line will deactivate dropouts\n",
    "test_loss, test_accuracy = 0, 0\n",
    "nb_test_steps, nb_test_examples = 0, 0\n",
    "pred_logits = []\n",
    "actual = []\n",
    "\n",
    "lrp_scores = []\n",
    "inputs_ids = []\n",
    "seqs_lens = []\n",
    "\n",
    "# we don't need gradient in this case.\n",
    "for step, batch in enumerate(tqdm(test_dataloader, desc=\"Iteration\")):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    input_ids, input_mask, segment_ids, label_ids, seq_lens = batch\n",
    "    # truncate to save space and computing resource\n",
    "    max_seq_lens = max(seq_lens)[0]\n",
    "    input_ids = input_ids[:,:max_seq_lens]\n",
    "    input_mask = input_mask[:,:max_seq_lens]\n",
    "    segment_ids = segment_ids[:,:max_seq_lens]\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    label_ids = label_ids.to(device)\n",
    "    seq_lens = seq_lens.to(device)\n",
    "\n",
    "    # intentially with gradient\n",
    "    tmp_test_loss, logits = \\\n",
    "        model(input_ids, segment_ids, input_mask, seq_lens,\n",
    "                device=device, labels=label_ids)\n",
    "\n",
    "    # for lrp\n",
    "    LRP_class = len(label_list) - 1\n",
    "    Rout_mask = torch.zeros((input_ids.shape[0], len(label_list))).to(device)\n",
    "    Rout_mask[:, LRP_class] = 1.0\n",
    "    relevance_score = logits*Rout_mask\n",
    "    lrp_score = model.backward_lrp(relevance_score).sum(dim=-1).cpu().data\n",
    "    input_ids = input_ids.cpu().data\n",
    "    seq_lens = seq_lens.cpu().data\n",
    "    lrp_scores.append(lrp_score)\n",
    "    inputs_ids.append(input_ids)\n",
    "    seqs_lens.append(seq_lens)\n",
    "    \n",
    "    # for gradient\n",
    "    \n",
    "    # for attention only tracing\n",
    "    \n",
    "    \n",
    "    logits = F.softmax(logits, dim=-1)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    pred_logits.append(logits)\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    actual.append(label_ids)\n",
    "    outputs = np.argmax(logits, axis=1)\n",
    "    tmp_test_accuracy=np.sum(outputs == label_ids)\n",
    "\n",
    "    test_loss += tmp_test_loss.mean().item()\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "\n",
    "    nb_test_examples += input_ids.size(0)\n",
    "    nb_test_steps += 1\n",
    "    \n",
    "test_loss = test_loss / nb_test_steps\n",
    "test_accuracy = test_accuracy / nb_test_examples\n",
    "\n",
    "result = collections.OrderedDict()\n",
    "result = {'test_loss': test_loss,\n",
    "            str(len(label_list))+ '-class test_accuracy': test_accuracy}\n",
    "logger.info(\"***** Eval results *****\")\n",
    "for key in result.keys():\n",
    "    logger.info(\"  %s = %s\\n\", key, str(result[key]))\n",
    "# get predictions needed for evaluation\n",
    "pred_logits = np.concatenate(pred_logits, axis=0)\n",
    "actual = np.concatenate(actual, axis=0)\n",
    "pred_label = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "lrp_state_dict = dict()\n",
    "lrp_state_dict[\"lrp_scores\"] = lrp_scores\n",
    "lrp_state_dict[\"inputs_ids\"] = inputs_ids\n",
    "lrp_state_dict[\"seqs_lens\"] = seqs_lens\n",
    "logger.info(\"***** Finish LRP *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregated lrp scores on a token aggregated across a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_mapping(vocab_dict):\n",
    "    inverse_vocab_dict = {}\n",
    "    for k, v in vocab_dict.items():\n",
    "        inverse_vocab_dict[v] = k\n",
    "    return inverse_vocab_dict\n",
    "\n",
    "def translate(token_ids, vocab):\n",
    "    tokens = []\n",
    "    for _id in token_ids.tolist():\n",
    "        tokens.append(vocab[_id])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SST-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = inverse_mapping(load_vocab(vocab_data_dir, pretrain=False))\n",
    "word_lrp = {}\n",
    "word_lrp_list = []\n",
    "for batch_idx in range(len(inputs_ids)):\n",
    "    for seq_idx in range(inputs_ids[batch_idx].shape[0]):\n",
    "        seq_len = seqs_lens[batch_idx][seq_idx].tolist()[0]\n",
    "        tokens = translate(inputs_ids[batch_idx][seq_idx], vocab)[:seq_len]\n",
    "        lrp_ss = lrp_scores[batch_idx][seq_idx].tolist()[:seq_len]\n",
    "        for i in range(len(tokens)):\n",
    "            word_lrp_list.append((tokens[i], lrp_ss[i]))\n",
    "            if tokens[i] in word_lrp.keys():\n",
    "                word_lrp[tokens[i]].append(lrp_ss[i])\n",
    "            else:\n",
    "                word_lrp[tokens[i]] = [lrp_ss[i]]\n",
    "filter_word_lrp = {}\n",
    "for k, v in word_lrp.items():\n",
    "    if len(v) > 1:\n",
    "        filter_word_lrp[k] = sum(v)*1.0/len(v)\n",
    "filter_word_lrp = [(k, v) for k, v in filter_word_lrp.items()] \n",
    "filter_word_lrp.sort(key = lambda x: x[1], reverse=True)  \n",
    "word_lrp_list.sort(key = lambda x: x[1], reverse=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actress', 1.1658735275268555),\n",
       " ('movie', 1.0500624179840088),\n",
       " ('!', 1.0485429763793945),\n",
       " ('disturbing', 1.0441009998321533),\n",
       " ('fascinating', 1.0142135620117188),\n",
       " ('i', 0.9432353377342224),\n",
       " ('loved', 0.9145122170448303),\n",
       " ('excellent', 0.8970187306404114),\n",
       " ('wonderful', 0.8715908527374268),\n",
       " ('documentary', 0.857614278793335),\n",
       " ('thriller', 0.8538416624069214),\n",
       " ('[SEP]', 0.8367592096328735),\n",
       " ('comedy', 0.8343492746353149),\n",
       " ('accessible', 0.8268217444419861),\n",
       " ('tremendous', 0.8265071511268616),\n",
       " ('[CLS]', 0.8011797666549683),\n",
       " ('enjoy', 0.7982317209243774),\n",
       " ('hilarious', 0.7917709350585938),\n",
       " ('funny', 0.7913933396339417),\n",
       " ('delightful', 0.7900826334953308)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lrp_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bother', -0.6187527179718018),\n",
       " ('caution', -0.6328242421150208),\n",
       " ('.', -0.6360901594161987),\n",
       " ('[SEP]', -0.6403815150260925),\n",
       " ('.', -0.6450625658035278),\n",
       " ('scenes', -0.6467615365982056),\n",
       " ('tale', -0.6688672304153442),\n",
       " ('[SEP]', -0.6737954020500183),\n",
       " ('why', -0.6740109920501709),\n",
       " ('.', -0.6845172643661499),\n",
       " ('weaker', -0.6860779523849487),\n",
       " ('[SEP]', -0.7098051905632019),\n",
       " ('[SEP]', -0.7335551977157593),\n",
       " ('[SEP]', -0.7473068237304688),\n",
       " ('search', -0.7814841270446777),\n",
       " ('fits', -0.7854188680648804),\n",
       " ('boring', -0.7887516021728516),\n",
       " ('hmm', -0.8135195970535278),\n",
       " ('sorry', -0.8380900621414185),\n",
       " ('confusing', -0.9827263355255127)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lrp_list[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exceeding', 0.5255683809518814),\n",
       " ('glorious', 0.523917555809021),\n",
       " ('amazing', 0.48885713145136833),\n",
       " ('amazingly', 0.4737926498055458),\n",
       " ('marvelous', 0.4553905725479126),\n",
       " ('observed', 0.40511031200488407),\n",
       " ('masterpiece', 0.3976913373917341),\n",
       " ('visuals', 0.3964625895023346),\n",
       " ('brutal', 0.3908869996666908),\n",
       " ('beautifully', 0.3795804445232664),\n",
       " ('wonderful', 0.37883903458714485),\n",
       " ('playful', 0.37169771393140155),\n",
       " ('remarkable', 0.36964475611845654),\n",
       " ('tremendous', 0.36521638184785843),\n",
       " ('manners', 0.36161354929208755),\n",
       " ('loved', 0.35561820715665815),\n",
       " ('impress', 0.3487958957751592),\n",
       " ('decade', 0.34550681710243225),\n",
       " ('troubled', 0.33895863592624664),\n",
       " ('landmark', 0.3376755118370056)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_word_lrp[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('derivative', -0.2808782085776329),\n",
       " ('wander', -0.28310608863830566),\n",
       " ('search', -0.2873449847102165),\n",
       " ('exercise', -0.2924286097288132),\n",
       " ('exploitation', -0.2969381492584944),\n",
       " ('##asse', -0.301093265414238),\n",
       " ('lifeless', -0.3042931407690048),\n",
       " ('cheese', -0.309484027326107),\n",
       " ('pluto', -0.3161681070923805),\n",
       " ('blur', -0.31875964999198914),\n",
       " ('##typical', -0.33823950588703156),\n",
       " ('scotland', -0.3510182946920395),\n",
       " ('rabbits', -0.35597583651542664),\n",
       " ('bother', -0.36322491243481636),\n",
       " ('trivial', -0.3873773664236069),\n",
       " ('sinks', -0.4133940041065216),\n",
       " ('progress', -0.45691321790218353),\n",
       " ('fits', -0.48892583698034286),\n",
       " ('confusing', -0.5344277396798134),\n",
       " ('sorry', -0.6642181724309921)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_word_lrp[-20:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
